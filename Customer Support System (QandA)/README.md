This project focuses on crucial aspects such as input moderation, prompt injection prevention, service request classification,
Chain of Thought Reasoning for user queries, and output evaluation.
Starting with input moderation, we utilize OpenAI's Moderation API to assess customer comments for appropriateness.
The project delves into prompt injection prevention, studying methods to secure language models and implementing safeguards.
Service request classification and logical response generation play key roles in ensuring effective customer assistance.
To validate system performance, a Model Self-Evaluation technique assesses factual accuracy by comparing responses with ideal answers.
